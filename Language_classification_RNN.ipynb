{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcLDKHJ6ckxOBAXj/2EVpY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samyarsworld/Language-classification-RNN/blob/main/Language_classification_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Detection"
      ],
      "metadata": {
        "id": "c-Sqcul1tCFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Download the project repository:\n",
        "\n",
        "Repository address: https://github.com/samyarsworld/Language-classification-RNN/tree/main\n",
        "\n",
        "The directory includes the data directory, a python utils file containing helper functions, and Python version of the code."
      ],
      "metadata": {
        "id": "4L6U-3nx4eRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/samyarsworld/Language-classification-RNN\n",
        "%cd Language-classification-RNN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_ef6OWw4uoW",
        "outputId": "06b6e4ad-e576-4044-f9c4-6f58bd8fc10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Language-classification-RNN'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/43)\u001b[K\rremote: Counting objects:   4% (2/43)\u001b[K\rremote: Counting objects:   6% (3/43)\u001b[K\rremote: Counting objects:   9% (4/43)\u001b[K\rremote: Counting objects:  11% (5/43)\u001b[K\rremote: Counting objects:  13% (6/43)\u001b[K\rremote: Counting objects:  16% (7/43)\u001b[K\rremote: Counting objects:  18% (8/43)\u001b[K\rremote: Counting objects:  20% (9/43)\u001b[K\rremote: Counting objects:  23% (10/43)\u001b[K\rremote: Counting objects:  25% (11/43)\u001b[K\rremote: Counting objects:  27% (12/43)\u001b[K\rremote: Counting objects:  30% (13/43)\u001b[K\rremote: Counting objects:  32% (14/43)\u001b[K\rremote: Counting objects:  34% (15/43)\u001b[K\rremote: Counting objects:  37% (16/43)\u001b[K\rremote: Counting objects:  39% (17/43)\u001b[K\rremote: Counting objects:  41% (18/43)\u001b[K\rremote: Counting objects:  44% (19/43)\u001b[K\rremote: Counting objects:  46% (20/43)\u001b[K\rremote: Counting objects:  48% (21/43)\u001b[K\rremote: Counting objects:  51% (22/43)\u001b[K\rremote: Counting objects:  53% (23/43)\u001b[K\rremote: Counting objects:  55% (24/43)\u001b[K\rremote: Counting objects:  58% (25/43)\u001b[K\rremote: Counting objects:  60% (26/43)\u001b[K\rremote: Counting objects:  62% (27/43)\u001b[K\rremote: Counting objects:  65% (28/43)\u001b[K\rremote: Counting objects:  67% (29/43)\u001b[K\rremote: Counting objects:  69% (30/43)\u001b[K\rremote: Counting objects:  72% (31/43)\u001b[K\rremote: Counting objects:  74% (32/43)\u001b[K\rremote: Counting objects:  76% (33/43)\u001b[K\rremote: Counting objects:  79% (34/43)\u001b[K\rremote: Counting objects:  81% (35/43)\u001b[K\rremote: Counting objects:  83% (36/43)\u001b[K\rremote: Counting objects:  86% (37/43)\u001b[K\rremote: Counting objects:  88% (38/43)\u001b[K\rremote: Counting objects:  90% (39/43)\u001b[K\rremote: Counting objects:  93% (40/43)\u001b[K\rremote: Counting objects:  95% (41/43)\u001b[K\rremote: Counting objects:  97% (42/43)\u001b[K\rremote: Counting objects: 100% (43/43)\u001b[K\rremote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/36)\u001b[K\rremote: Compressing objects:   5% (2/36)\u001b[K\rremote: Compressing objects:   8% (3/36)\u001b[K\rremote: Compressing objects:  11% (4/36)\u001b[K\rremote: Compressing objects:  13% (5/36)\u001b[K\rremote: Compressing objects:  16% (6/36)\u001b[K\rremote: Compressing objects:  19% (7/36)\u001b[K\rremote: Compressing objects:  22% (8/36)\u001b[K\rremote: Compressing objects:  25% (9/36)\u001b[K\rremote: Compressing objects:  27% (10/36)\u001b[K\rremote: Compressing objects:  30% (11/36)\u001b[K\rremote: Compressing objects:  33% (12/36)\u001b[K\rremote: Compressing objects:  36% (13/36)\u001b[K\rremote: Compressing objects:  38% (14/36)\u001b[K\rremote: Compressing objects:  41% (15/36)\u001b[K\rremote: Compressing objects:  44% (16/36)\u001b[K\rremote: Compressing objects:  47% (17/36)\u001b[K\rremote: Compressing objects:  50% (18/36)\u001b[K\rremote: Compressing objects:  52% (19/36)\u001b[K\rremote: Compressing objects:  55% (20/36)\u001b[K\rremote: Compressing objects:  58% (21/36)\u001b[K\rremote: Compressing objects:  61% (22/36)\u001b[K\rremote: Compressing objects:  63% (23/36)\u001b[K\rremote: Compressing objects:  66% (24/36)\u001b[K\rremote: Compressing objects:  69% (25/36)\u001b[K\rremote: Compressing objects:  72% (26/36)\u001b[K\rremote: Compressing objects:  75% (27/36)\u001b[K\rremote: Compressing objects:  77% (28/36)\u001b[K\rremote: Compressing objects:  80% (29/36)\u001b[K\rremote: Compressing objects:  83% (30/36)\u001b[K\rremote: Compressing objects:  86% (31/36)\u001b[K\rremote: Compressing objects:  88% (32/36)\u001b[K\rremote: Compressing objects:  91% (33/36)\u001b[K\rremote: Compressing objects:  94% (34/36)\u001b[K\rremote: Compressing objects:  97% (35/36)\u001b[K\rremote: Compressing objects: 100% (36/36)\u001b[K\rremote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "Receiving objects:   2% (1/43)\rReceiving objects:   4% (2/43)\rReceiving objects:   6% (3/43)\rReceiving objects:   9% (4/43)\rReceiving objects:  11% (5/43)\rReceiving objects:  13% (6/43)\rReceiving objects:  16% (7/43)\rReceiving objects:  18% (8/43)\rReceiving objects:  20% (9/43)\rReceiving objects:  23% (10/43)\rReceiving objects:  25% (11/43)\rReceiving objects:  27% (12/43)\rReceiving objects:  30% (13/43)\rReceiving objects:  32% (14/43)\rReceiving objects:  34% (15/43)\rReceiving objects:  37% (16/43)\rReceiving objects:  39% (17/43)\rReceiving objects:  41% (18/43)\rReceiving objects:  44% (19/43)\rReceiving objects:  46% (20/43)\rReceiving objects:  48% (21/43)\rReceiving objects:  51% (22/43)\rReceiving objects:  53% (23/43)\rReceiving objects:  55% (24/43)\rReceiving objects:  58% (25/43)\rReceiving objects:  60% (26/43)\rReceiving objects:  62% (27/43)\rReceiving objects:  65% (28/43)\rReceiving objects:  67% (29/43)\rremote: Total 43 (delta 4), reused 13 (delta 2), pack-reused 0\u001b[K\n",
            "Receiving objects:  69% (30/43)\rReceiving objects:  72% (31/43)\rReceiving objects:  74% (32/43)\rReceiving objects:  76% (33/43)\rReceiving objects:  79% (34/43)\rReceiving objects:  81% (35/43)\rReceiving objects:  83% (36/43)\rReceiving objects:  86% (37/43)\rReceiving objects:  88% (38/43)\rReceiving objects:  90% (39/43)\rReceiving objects:  93% (40/43)\rReceiving objects:  95% (41/43)\rReceiving objects:  97% (42/43)\rReceiving objects: 100% (43/43)\rReceiving objects: 100% (43/43), 66.73 KiB | 6.67 MiB/s, done.\n",
            "Resolving deltas:   0% (0/4)\rResolving deltas:  25% (1/4)\rResolving deltas:  50% (2/4)\rResolving deltas:  75% (3/4)\rResolving deltas: 100% (4/4)\rResolving deltas: 100% (4/4), done.\n",
            "/content/Language-classification-RNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Install the necessary libraries:\n",
        "Make sure Python (recommended 3.10) and pip (recommended 23.3.1) are installed."
      ],
      "metadata": {
        "id": "p20wq7qePl5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "c1NPQeDvPtgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Import Required Libraries and Functions:"
      ],
      "metadata": {
        "id": "64FohhvJ6RSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from utils import load_data, letter_to_tensor, sentence_to_tensor, LETTERS, get_random_sample\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "l374yQKm6Uzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Setup Initial Configurations:"
      ],
      "metadata": {
        "id": "ffLv0fpK7FKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "languages, language_names = load_data()\n",
        "\n",
        "MODEL_PATH = Path(\"./model.pt\")\n",
        "N_HIDDEN = 128  # Number of hidden units\n",
        "EPOCHS = 300000\n",
        "STEPS = 1000"
      ],
      "metadata": {
        "id": "ERuft1hD7G78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Create RNN Model:"
      ],
      "metadata": {
        "id": "WJpNVWAT7HHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size) -> None:\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(in_features=input_size + hidden_size, out_features=hidden_size)\n",
        "        self.i2o = nn.Linear(in_features=input_size + hidden_size, out_features=output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, h: torch.Tensor) -> torch.Tensor:\n",
        "        combined_tensor = torch.cat((x, h), dim=1)\n",
        "        return self.softmax(self.i2o(combined_tensor)), self.i2h(combined_tensor)"
      ],
      "metadata": {
        "id": "3obaRTYx7PFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model\n",
        "RNN_model = RNN(len(LETTERS), N_HIDDEN, len(languages))"
      ],
      "metadata": {
        "id": "9aua3q-XSMet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Trainin Setup:"
      ],
      "metadata": {
        "id": "_zT-ujotSlDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer\n",
        "LR = 0.005\n",
        "optimizer = torch.optim.SGD(params=RNN_model.parameters(), lr=LR)\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.NLLLoss()\n",
        "current_loss = 0.0\n",
        "all_losses = []"
      ],
      "metadata": {
        "id": "uMaVI9rlS3o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training setup\n",
        "def train(name_tensor, language_tensor):\n",
        "    next_hidden = RNN_model.init_hidden()\n",
        "\n",
        "    for i in range(name_tensor.size()[0]):\n",
        "        output, next_hidden = RNN_model(name_tensor[i], next_hidden)\n",
        "\n",
        "    loss = criterion(output, language_tensor)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return output, loss.item()"
      ],
      "metadata": {
        "id": "hbSKbI2kSzki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Train the Model:"
      ],
      "metadata": {
        "id": "wnmFuaZDS4bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model if exists\n",
        "if MODEL_PATH.exists():\n",
        "  RNN_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "  assert(\"Model was SUCCESSFULLY loaded.\")\n",
        "else:\n",
        "  assert(\"Model does NOT exist.\")\n"
      ],
      "metadata": {
        "id": "MO8Wf_HhSa2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run traning if the model doesn't exist or needs more training\n",
        "for epoch in range(EPOCHS):\n",
        "        language, language_tensor, name,  name_tensor = get_random_sample(languages, language_names)\n",
        "        output, loss = train(name_tensor, language_tensor)\n",
        "        current_loss += loss\n",
        "\n",
        "        if epoch % STEPS == 0:\n",
        "            all_losses.append(current_loss / STEPS)\n",
        "            current_loss = 0\n",
        "\n",
        "            prediction = languages[torch.argmax(output).item()]\n",
        "            correct = \"CORRECT\" if prediction == language else f\"WRONG -> {language}\"\n",
        "            print(f\"{epoch} {epoch / EPOCHS * 100:.0f} {loss:.5f} {name} / {prediction} {correct}\")\n",
        "\n",
        "    # Save the model to local disk\n",
        "    torch.save(RNN_model.state_dict(), MODEL_PATH)"
      ],
      "metadata": {
        "id": "ubHl4KIPTtnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Plot Training Losses:"
      ],
      "metadata": {
        "id": "lA2SLFEjSeBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot losses per 1000 words\n",
        "plt.plot(all_losses[1:-1], label='Loss', marker='o', linestyle='-')\n",
        "\n",
        "# Adding titles and labels\n",
        "plt.title('Plot Title')\n",
        "plt.xlabel('X-axis Label')\n",
        "plt.ylabel('Y-axis Label')\n",
        "\n",
        "# Adding a legend\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O7mY6qNFSf-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Perform Predictions:"
      ],
      "metadata": {
        "id": "E-Xlw8S2TF4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    print(f\"\\n> {sentence}\")\n",
        "    with torch.inference_mode():\n",
        "        name_tensor = sentence_to_tensor(sentence)\n",
        "\n",
        "        next_hidden = RNN_model.init_hidden()\n",
        "\n",
        "        for i in range(name_tensor.size()[0]):\n",
        "            output, next_hidden = RNN_model(name_tensor[i], next_hidden)\n",
        "\n",
        "        prediction = languages[torch.argmax(output).item()]\n",
        "        print(prediction)\n",
        "\n",
        "# Prediction state\n",
        "while True:\n",
        "    sentence = input(\"Input:\")\n",
        "    if sentence == \"q\":\n",
        "        break\n",
        "    else:\n",
        "        predict(sentence)"
      ],
      "metadata": {
        "id": "fOMsbrReTJvM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}